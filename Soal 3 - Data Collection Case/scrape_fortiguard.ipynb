{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rKsyEVSWsBok",
        "outputId": "eedcbf48-24db-48f9-986b-69ec4fd13137"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting httpx\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (4.12.3)\n",
            "Requirement already satisfied: polars in /usr/local/lib/python3.10/dist-packages (0.20.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.4)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx) (2024.6.2)\n",
            "Collecting httpcore==1.* (from httpx)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx) (3.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx) (1.3.1)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4) (2.5)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx) (1.2.1)\n",
            "Installing collected packages: h11, httpcore, httpx\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.0\n"
          ]
        }
      ],
      "source": [
        "pip install httpx beautifulsoup4 polars tqdm\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import httpx\n",
        "import asyncio\n",
        "from bs4 import BeautifulSoup\n",
        "import polars as pl\n",
        "from tqdm.asyncio import tqdm\n",
        "import json"
      ],
      "metadata": {
        "id": "w8K65kJdsHJg"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs('datasets', exist_ok=True)\n",
        "\n",
        "max_pages = [10, 20, 5, 15, 25]  # Define the maximum pages for each level\n",
        "base_url = \"https://www.fortiguard.com/encyclopedia?type=ips&risk={level}&page={i}\"\n",
        "\n",
        "skipped_pages = {}\n"
      ],
      "metadata": {
        "id": "CSyZc1x3tcbZ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "async def fetch_page(client, url, level, page):\n",
        "    try:\n",
        "        response = await client.get(url, timeout=10.0)\n",
        "        response.raise_for_status()\n",
        "        return response.text\n",
        "    except (httpx.RequestError, httpx.HTTPStatusError) as exc:\n",
        "        skipped_pages.setdefault(level, []).append(page)\n",
        "        return None"
      ],
      "metadata": {
        "id": "IkEn3Ub6teo_"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "async def fetch_level_data(level, max_page):\n",
        "    data = []\n",
        "    async with httpx.AsyncClient() as client:\n",
        "        tasks = []\n",
        "        for i in range(1, max_page + 1):\n",
        "            url = base_url.format(level=level, i=i)\n",
        "            tasks.append(fetch_page(client, url, level, i))\n",
        "\n",
        "        responses = await tqdm.gather(*tasks, desc=f\"Fetching level {level}\", ncols=100)\n",
        "\n",
        "        for page, html in enumerate(responses, 1):\n",
        "            if html:\n",
        "                soup = BeautifulSoup(html, 'html.parser')\n",
        "                articles = soup.select('.threat-detail > a')\n",
        "                for article in articles:\n",
        "                    title = article.get_text(strip=True)\n",
        "                    link = article['href']\n",
        "                    data.append({\"title\": title, \"link\": link})\n",
        "    return data\n",
        "\n"
      ],
      "metadata": {
        "id": "LS9Gntrss1TW"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "async def main():\n",
        "    tasks = []\n",
        "    for level, max_page in enumerate(max_pages, 1):\n",
        "        tasks.append(fetch_level_data(level, max_page))\n",
        "\n",
        "    results = await asyncio.gather(*tasks)\n",
        "\n",
        "    for level, data in enumerate(results, 1):\n",
        "        df = pl.DataFrame(data)\n",
        "        df.write_csv(f'datasets/forti_lists_{level}.csv')\n",
        "\n",
        "    with open('datasets/skipped.json', 'w') as f:\n",
        "        json.dump(skipped_pages, f, indent=4)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    await main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "107UGu53tEiq",
        "outputId": "ad6cf21b-2099-4b58-f3a7-bd67871c5d82"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fetching level 1:   0%|                                                      | 0/10 [00:00<?, ?it/s]\n",
            "Fetching level 2:   0%|                                                      | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "Fetching level 3:   0%|                                                       | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Fetching level 4:   0%|                                                      | 0/15 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Fetching level 5:   0%|                                                      | 0/25 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "Fetching level 2:   5%|██▎                                           | 1/20 [00:08<02:49,  8.90s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Fetching level 5:   4%|█▊                                            | 1/25 [00:09<03:39,  9.16s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Fetching level 1:  10%|████▌                                         | 1/10 [00:10<01:34, 10.49s/it]\n",
            "Fetching level 2:  10%|████▌                                         | 2/20 [00:10<01:22,  4.59s/it]\u001b[A\n",
            "\n",
            "\n",
            "Fetching level 4:  13%|██████▏                                       | 2/15 [00:10<00:55,  4.28s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Fetching level 3:  20%|█████████▍                                     | 1/5 [00:10<00:41, 10.41s/it]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Fetching level 2: 100%|█████████████████████████████████████████████| 20/20 [00:10<00:00,  1.89it/s]\n",
            "\n",
            "\n",
            "Fetching level 3:  60%|████████████████████████████▏                  | 3/5 [00:10<00:05,  2.76s/it]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Fetching level 4: 100%|█████████████████████████████████████████████| 15/15 [00:10<00:00,  1.42it/s]\n",
            "\n",
            "\n",
            "Fetching level 3: 100%|███████████████████████████████████████████████| 5/5 [00:10<00:00,  2.14s/it]\n",
            "Fetching level 1: 100%|█████████████████████████████████████████████| 10/10 [00:10<00:00,  1.08s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Fetching level 5: 100%|█████████████████████████████████████████████| 25/25 [00:10<00:00,  2.37it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "29t0DjZBtlYR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}