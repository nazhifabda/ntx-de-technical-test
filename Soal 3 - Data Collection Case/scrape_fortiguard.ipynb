{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rKsyEVSWsBok",
        "outputId": "56da90d4-fdcc-4546-840c-688b1ec0b4d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (0.27.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (4.12.3)\n",
            "Requirement already satisfied: polars in /usr/local/lib/python3.10/dist-packages (0.20.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.4)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx) (2024.6.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx) (1.0.5)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx) (3.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx) (0.14.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4) (2.5)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx) (1.2.1)\n"
          ]
        }
      ],
      "source": [
        "pip install httpx beautifulsoup4 polars tqdm\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import httpx\n",
        "import asyncio\n",
        "from bs4 import BeautifulSoup\n",
        "import polars as pl\n",
        "from tqdm.asyncio import tqdm\n",
        "import json"
      ],
      "metadata": {
        "id": "w8K65kJdsHJg"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs('datasets', exist_ok=True)\n",
        "\n",
        "max_pages = [10, 20, 5, 15, 25]  # Define the maximum pages for each level\n",
        "base_url = \"https://www.fortiguard.com/encyclopedia?type=ips&risk={level}&page={i}\"\n",
        "\n",
        "skipped_pages = {}\n"
      ],
      "metadata": {
        "id": "CSyZc1x3tcbZ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "async def fetch_page(client, url, level, page):\n",
        "    try:\n",
        "        response = await client.get(url, timeout=10.0)\n",
        "        response.raise_for_status()\n",
        "        return response.text\n",
        "    except (httpx.RequestError, httpx.HTTPStatusError) as exc:\n",
        "        skipped_pages.setdefault(level, []).append(page)\n",
        "        return None"
      ],
      "metadata": {
        "id": "IkEn3Ub6teo_"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "async def fetch_level_data(level, max_page):\n",
        "    data = []\n",
        "    async with httpx.AsyncClient() as client:\n",
        "        tasks = []\n",
        "        for i in range(1, max_page + 1):\n",
        "            url = base_url.format(level=level, i=i)\n",
        "            tasks.append(fetch_page(client, url, level, i))\n",
        "\n",
        "        responses = await tqdm.gather(*tasks, desc=f\"Fetching level {level}\", ncols=100)\n",
        "\n",
        "        for page, html in enumerate(responses, 1):\n",
        "            if html:\n",
        "                soup = BeautifulSoup(html, 'html.parser')\n",
        "                articles = soup.select('.threat-detail > a')\n",
        "                for article in articles:\n",
        "                    title = article.get_text(strip=True)\n",
        "                    link = article['href']\n",
        "                    data.append({\"title\": title, \"link\": link})\n",
        "    return data\n",
        "\n"
      ],
      "metadata": {
        "id": "LS9Gntrss1TW"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "async def main():\n",
        "    tasks = []\n",
        "    for level, max_page in enumerate(max_pages, 1):\n",
        "        tasks.append(fetch_level_data(level, max_page))\n",
        "\n",
        "    results = await asyncio.gather(*tasks)\n",
        "\n",
        "    for level, data in enumerate(results, 1):\n",
        "        df = pl.DataFrame(data)\n",
        "        df.write_csv(f'datasets/forti_lists_{level}.csv')\n",
        "\n",
        "    with open('datasets/skipped.json', 'w') as f:\n",
        "        json.dump(skipped_pages, f, indent=4)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    await main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "107UGu53tEiq",
        "outputId": "3a784208-30d6-4625-9927-f7aa463bd7fc"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fetching level 1:   0%|                                                      | 0/10 [00:00<?, ?it/s]\n",
            "Fetching level 2:   0%|                                                      | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "Fetching level 3:   0%|                                                       | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Fetching level 4:   0%|                                                      | 0/15 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Fetching level 1:  50%|███████████████████████                       | 5/10 [00:10<00:07,  1.54s/it]\n",
            "\n",
            "\n",
            "\n",
            "Fetching level 1:  80%|████████████████████████████████████▊         | 8/10 [00:10<00:01,  1.25it/s]\n",
            "Fetching level 1: 100%|█████████████████████████████████████████████| 10/10 [00:10<00:00,  1.09s/it]\n",
            "\n",
            "\n",
            "Fetching level 3: 100%|███████████████████████████████████████████████| 5/5 [00:11<00:00,  2.21s/it]\n",
            "\n",
            "Fetching level 2: 100%|█████████████████████████████████████████████| 20/20 [00:11<00:00,  1.80it/s]\n",
            "\n",
            "\n",
            "\n",
            "Fetching level 4: 100%|█████████████████████████████████████████████| 15/15 [00:10<00:00,  1.36it/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Fetching level 5: 100%|█████████████████████████████████████████████| 25/25 [00:10<00:00,  2.29it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "29t0DjZBtlYR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}